{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоговая аттестация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "Выполните задания, используя jupyter.\n",
    "Для решения итогового проекта выберете наиболее подходящий для вас датасет из списка: Задания для итоговой аттестации\n",
    "Вы выбрали Dataset из списка - [Gender Classification Dataset](https://www.kaggle.com/datasets/elakiricoder/gender-classification-dataset/data), проведите полный цикл работы над вашим проектом, что проходили ранее. \n",
    "\n",
    "### Pipeline выполнения задачи:\n",
    "\n",
    "1. Загрузка и предобработка данных \n",
    "\n",
    "2. Описательный анализ данных, просмотр данных и вывод статистики\n",
    "\n",
    "3. Постройте необходимые графики для анализа\n",
    "\n",
    "4. Проверьте гипотезы (если потребуется)\n",
    "\n",
    "5. Сделайте промежуточный отчет-вывод по исследованию\n",
    "\n",
    "6. Определите, какую задачу вы будете решать (классификация, регрессия и т.д.)\n",
    "\n",
    "7. Создайте несколько моделей для прогнозирования вашего целевого признака и выберите наилучшую, опираясь на вашу валидацию\n",
    "\n",
    "8. Сделайте прогноз для тестовой выборки (должно быть три выборки в этой задаче: тренировочная, валидационная, тестовая)\n",
    "\n",
    "9. Приведите метрику, с помощью которой вы будете оценивать работу вашей модели (обоснуйте ваш выбор метрики)\n",
    "\n",
    "10. Сделайте вывод о работе вашей модели и метриках. Обоснуйте: «Нужно ли использовать для решения этой задачи машинное обучение или можно обойтись dummy-предсказанием?»\n",
    "\n",
    "### Рекомендации:\n",
    "\n",
    "- Соблюдайте PEP8\n",
    "\n",
    "- Комментируйте код в местах, где конструкция большая\n",
    "\n",
    "- Оставляйте промежуточные выводы по вашему исследованию и построению модели (так кураторам будет проще понять ваши заключения)\n",
    "\n",
    "- Экспериментируйте! Вы не ограничены в моделях и подходах. Можете использовать любые DS инструменты (и те, которые мы не разбирали с вами на курсе)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и предобработка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'./gender_classification_v7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ознакомимся с датасетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем и подготовим датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df.duplicated().sum()\n",
    "\n",
    "print(f'Количество дублей: {duplicates}')\n",
    "\n",
    "if duplicates > 0:\n",
    "    df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готово! Датасет загружен, обработан и подготовлен для анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Описательный анализ данных, просмотр данных и вывод статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание датасета\n",
    "Этот набор данных содержит 7 признаков и столбец с метками.\n",
    "\n",
    "- **long_hair** – Этот столбец содержит 0 и 1, где 1 – \"длинные волосы\", а 0 – \"не длинные волосы\".\n",
    "- **forehead_width_cm** – Ширина лба в сантиметрах.\n",
    "- **forehead_height_cm** – Высота лба в сантиметрах.\n",
    "- **nose_wide** – Этот столбец содержит 0 и 1, где 1 – \"широкий нос\", а 0 – \"не широкий нос\".\n",
    "- **nose_long** – Этот столбец содержит 0 и 1, где 1 – \"длинный нос\", а 0 – \"не длинный нос\".\n",
    "- **lips_thin** – Этот столбец содержит 0 и 1, где 1 – \"тонкие губы\", а 0 – \"не тонкие губы\".\n",
    "- **distance_nose_to_lip_long** – Этот столбец содержит 0 и 1, где 1 – \"большое расстояние между носом и губами\", а 0 – \"маленькое расстояние между носом и губами\".\n",
    "\n",
    "- **gender** – Метка: \"Male\" или \"Female\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Общий вывод по данным:\n",
    "\n",
    "1. **Длинные волосы (long_hair)**:\n",
    "   - У большинства (82%) есть длинные волосы, что видно из среднего значения 0.82.\n",
    "   - Стандартное отклонение низкое 0.38, данные распределены близко к среднему. \n",
    "   - Минимум — 0 (нет длинных волос), максимум — 1 (длинные волосы). Входят сюда лысые люди - вопрос остается открытым.\n",
    "\n",
    "2. **Ширина лба (forehead_width_cm)**:\n",
    "   - В среднем ширина лба — **13.2 см**.\n",
    "   - Самые узкие — 11.4 см, самые широкие — 15.5 см.\n",
    "   - Большинство людей имеют ширину лба от 12.3 до 14.1 см.\n",
    "\n",
    "3. **Высота лба (forehead_height_cm)**:\n",
    "   - Средняя высота — **5.97 см**, небольшой разброс данных, стандартное отклонение — 0.55.\n",
    "   - Минимум — 5.1 см, максимум — 7.1 см. Большинство значений в диапазоне от 5.5 до 6.4 см.\n",
    "\n",
    "4. **Широкий нос (nose_wide)**:\n",
    "   - Примерно 54% людей имеют широкий нос, а 46% — нет.\n",
    "   - Разброс значений практически одинаковый.\n",
    "\n",
    "5. **Длинный нос (nose_long)**:\n",
    "   - Ситуация похожа на широкий нос — 55.7% имеют длинный нос, 44.3% — нет.\n",
    "   - Стандартное отклонение 0.50 говорит о равномерном распределении.\n",
    "\n",
    "6. **Тонкие губы (lips_thin)**:\n",
    "   - У 54% тонкие губы, у 46% — нет.\n",
    "   - Значения распределены равномерно.\n",
    "\n",
    "7. **Длинное расстояние от носа до губ (distance_nose_to_lip_long)**:\n",
    "   - У 54.5% расстояние длинное, у 45.5% — короткое.\n",
    "   - Тоже равномерное распределение.\n",
    "\n",
    "### На что я обратил внимание:\n",
    "- У большинства есть длинные волосы, что сильно выделяется среди остальных признаков.\n",
    "- Бинарные признаки (широкий/длинный нос, тонкие губы и т.д.) сбалансированы, нет значительного завала в одну из сторон.\n",
    "- Метрики, такие как ширина и высота лба, имеют небольшой разброс и находятся в адекватных значений.\n",
    "\n",
    "*Повезло - очень приятный датасет в плане данных и их качества =)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Построим необходимые графики для анализа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение распределений числовых признаков по полу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "numerical_features = ['forehead_width_cm', 'forehead_height_cm']\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    sns.histplot(data=df, x=feature, hue='gender', kde=True, bins=30, ax=axes[i])\n",
    "    axes[i].set_title(f'Распределение {feature} по полу', fontsize=12)\n",
    "    axes[i].set_xlabel(f'{feature} (см)', fontsize=10)\n",
    "    axes[i].set_ylabel('Частота', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков распределения бинарных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "binary_features = ['long_hair', 'nose_wide', 'nose_long', 'lips_thin', 'distance_nose_to_lip_long']\n",
    "for i, feature in enumerate(binary_features):\n",
    "    sns.countplot(data=df, x=feature, hue='gender', ax=axes[i])\n",
    "    axes[i].set_title(f'Распределение {feature} по полу', fontsize=12)\n",
    "    axes[i].set_xlabel(feature, fontsize=10)\n",
    "    axes[i].set_ylabel('Количество', fontsize=10)\n",
    "\n",
    "if len(binary_features) < len(axes):\n",
    "    for j in range(len(binary_features), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут хорошо подойдет матрица корреляции Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование колонки gender в бинарный вид для матрицы корреляции\n",
    "df['gender'] = df['gender'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "correlation_matrix = df.corr(method='spearman')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', cbar=True)\n",
    "plt.title('Матрица корреляции Spearman')\n",
    "plt.show()\n",
    "\n",
    "# Возвращение колонки gender в исходный формат, пока что\n",
    "df['gender'] = df['gender'].map({0: 'Male', 1: 'Female'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на баланс классов в целевой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Баланс классов в целевой выборке:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=y.value_counts().index, y=y.value_counts().values)\n",
    "plt.title('Баланс классов в целевой выборке')\n",
    "plt.xlabel('Класс')\n",
    "plt.ylabel('Количество')\n",
    "plt.xticks(ticks=[0, 1], labels=['Мужчины', 'Женщины'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баланс классов в целевой выборке говорит, что классы мужчин и женщин немного несбалансированы, но не критически, примерно 55:45. Исходя из этого, есть смысл в дальнейшем использовать *class_weight='balanced'* в некоторых моделях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Проверка гипотез (если потребуется)\n",
    "\n",
    "Не вижу в этом необходимости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Промежуточный отчет-вывод по исследованию по исследованию графиков:\n",
    "\n",
    "1. **Распределение ширины и высоты лба:**\n",
    "   - **Ширина лба (`forehead_width_cm`)** - вижу похожие распределения для мужчин и женщин, но у женщин виден небольшой сдвиг влево. Мужчины имеют побольше диапазон.\n",
    "   - **Высота лба (`forehead_height_cm`)** - здесь схожая ситуация, но у женщин распределение смещено влево, похоже у них более высокие значения в среднем.\n",
    "\n",
    "2. **Распределение бинарных признаков:**\n",
    "   - **Длинные волосы (`long_hair`)** - предсказуемо, большинство женщин имеют длинные волосы, в то время как у мужчин короткие.\n",
    "   - **Широкий нос (`nose_wide`) и длинный нос (`nose_long`)** - у мужчин эти признаки встречаются чаще, это неплохой маркер.\n",
    "   - **Тонкие губы (`lips_thin`)** - признак характеризующий мужчин.\n",
    "   - **Большое расстояние между носом и губами (`distance_nose_to_lip_long`)** - также чаще видим у мужчин.\n",
    "\n",
    "3. **Матрица корреляции (Spearman):**\n",
    "   - Яркая сильная отрицательная корреляция наблюдается между полом и признаками: `nose_wide`, `nose_long`, `lips_thin` и `distance_nose_to_lip_long`. Похоже, что это зависимости которые мы ищем.\n",
    "   - Признаки ширина и высота лба имеют более слабую корреляцию с таргетом, что делает их вклад слабым в предсказания пола. Думаю их можно будет выкинуть при обучении. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Определим, какую задачу мы будете решать (классификация, регрессия и т.д.)\n",
    "\n",
    "Очевидно, что **классификации**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Создадим несколько моделей для прогнозирования нашего целевого признака и выберем наилучшую, опираясь на нашу валидацию\n",
    "\n",
    "В рамках этого же блока:\n",
    "- Сделаем прогноз для тестовой выборки (должно быть три выборки в этой задаче: тренировочная, валидационная, тестовая)\n",
    "- Приведем метрики, с помощью которых будем оценивать работу моделей (обоснуем выбор метрик)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовим все необходимое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем данные\n",
    "features = df.drop(columns=['gender'])\n",
    "target = df['gender']\n",
    "\n",
    "# Трансформер целевого признака в бинарный вид\n",
    "def transform_target(transform_target):\n",
    "    return transform_target.map({'Male': 0, 'Female': 1})\n",
    "\n",
    "# Функция удаления слабых признаков\n",
    "def drop_weak_features(features):\n",
    "    return features.drop(columns=['forehead_width_cm', 'forehead_height_cm'])\n",
    "\n",
    "# Преобразуем целевой признак в бинарный вид\n",
    "target = transform_target(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Инициализируем пайплайн для обработки данных и сами модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Pipeline(steps=[\n",
    "    ('drop_features', FunctionTransformer(drop_weak_features)),\n",
    "    # Не забудем о нормализация признаков\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Из аналитики помним что есть небольшой дисбаланс классов, устраним это\n",
    "\n",
    "logistic_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "nn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', MLPClassifier(random_state=42, max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Были выбраны следующие модели:\n",
    "\n",
    "- **Логистическая регрессия**:\n",
    "Это базовая линейная модель, часто используется для задач классификации.\n",
    "\n",
    "- **Случайный лес**:\n",
    "Ансамблевый метод основаный на деревьях решений и хорошо работает с нелинейными зависимостями. Автоматически выявляет важность признаков и устойчив к шуму.\n",
    "Хорошо справляется с дисбалансом классов.\n",
    "\n",
    "- **Полносвязная нейронная сеть**:\n",
    "Она улавливает сложные нелинейные зависимости в данных. Взята ради эксперемента и интереса. <details>\n",
    "  <summary>Спойлер.</summary>\n",
    "  Не зря =)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разделим данные и обучим модели на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(features, target, test_size=0.4, random_state=42, stratify=target)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "logistic_pipeline.fit(X_train, y_train)\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "nn_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предсказажем на валидационной выборке и сделаем оценку моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_preds = logistic_pipeline.predict(X_val)\n",
    "rf_preds = rf_pipeline.predict(X_val)\n",
    "nn_preds = nn_pipeline.predict(X_val)\n",
    "\n",
    "logistic_acc = accuracy_score(y_val, logistic_preds)\n",
    "rf_acc = accuracy_score(y_val, rf_preds)\n",
    "nn_acc = accuracy_score(y_val, nn_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Выбраные метрики:\n",
    "\n",
    "- **(Accuracy)**:\n",
    "Точность показывает, какую долю правильных предсказаний модель делает в общем числе примеров. Это простая метрика, полезная, если классы сбалансированы (мы это учли).\n",
    "\n",
    "- **F1-score**:\n",
    "F1-score — это гармоническое среднее между точностью и полнотой, что делает её устойчивой к дисбалансу классов.\n",
    "Включим эту метрику с помощью classification_report чуть дальше.\n",
    "\n",
    "- **Confusion Matrix**:\n",
    "Матрица ошибок визуализирует, сколько примеров каждого класса модель классифицировала правильно и где она ошиблась. Помогает понять, какие ошибки допускаются чаще — ложноположительные или ложноотрицательные.\n",
    "Полезна с несбалансированными данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравним модели и построим графики для оценки качества моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Neural Network'],\n",
    "    'Validation Accuracy': [logistic_acc, rf_acc, nn_acc]\n",
    "})\n",
    "\n",
    "# Сравним модели\n",
    "print(\"Результаты сравнения моделей:\\n\\n\", results)\n",
    "\n",
    "models = {'Logistic Regression': logistic_pipeline, \n",
    "          'Random Forest': rf_pipeline, \n",
    "          'Neural Network': nn_pipeline}\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('Матрицы ошибок для моделей', fontsize=16)\n",
    "\n",
    "# Построим матрицу ошибок для каждой модели\n",
    "for ax, (name, model) in zip(axes, models.items()):\n",
    "    y_pred = model.predict(X_test)\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test, y_pred, display_labels=['Мужчины', 'Женщины'], cmap='Purples', ax=ax\n",
    "    )\n",
    "    ax.set_title(f'Матрица ошибок: {name}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем отдельно ROC-AUC для нашей полносвязной нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_probs = nn_pipeline.predict_proba(X_test)[:, 1]  # Вероятности для класса женщины\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, nn_probs)\n",
    "print(f\"ROC-AUC для нейронной сети: {roc_auc:.3f}\\n\")\n",
    "\n",
    "# Построение ROC-кривой\n",
    "fpr, tpr, thresholds = roc_curve(y_test, nn_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Нейронная сеть (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='\"Пальцем в небо\"')\n",
    "plt.title('ROC-кривая для нейронной сети')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка метрик для каждой модели на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"{name}:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Мужчины', 'Женщины']))\n",
    "    print(\"-\" * 70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Все, что нужно мы сделали и получили все метрики, можно перейти к выводам.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Сделаем вывод о работе наших моделей и метриках. \n",
    "*Обоснуем: «Нужно ли использовать для решения этой задачи машинное обучение или можно обойтись dummy-предсказанием?»*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все три модели **Logistic Regression, Random Forest** и **Neural Network** продемонстрировали похожие результаты:\n",
    "- **Точность (accuracy)** составила **94%** для всех моделей.\n",
    "- Метрики **precision**, **recall**, и **F1-score** показывают сбалансированные значения для обоих классов.\n",
    "- **ROC-AUC для нейронной сети** равный 0.985 доказывает, что модель отлично предсказывает классы.\n",
    "\n",
    "Все модели успешно справляются с задачей, дают высокую точность предсказаний для предсказания пола.\n",
    "\n",
    "### Обоснование: машинное обучение или dummy-предсказание?\n",
    "\n",
    "*Dummy-предсказание* — если верить википедии, это стратегия, при которой модель либо случайно угадывает классы, либо всегда выбирает наиболее частый класс.\n",
    "\n",
    "В нашем случае это дало бы:\n",
    "- Точность **~55%**, так как класс \"Мужчины\" составляет ~55% от всех данных.\n",
    "- Метрики **precision, recall, F1-score** были бы низкими для \"женщин\", поскольку модель почти никогда не предсказывала бы этот класс.\n",
    "\n",
    "**Сравнение**:\n",
    "- Наше машинное обучение даёт точность **94%**, что значительно больше пресловутых **55%**.\n",
    "- Все модели успешно справляются с классификацией, избегая склонности просто \"выбирать мужчин\".\n",
    "\n",
    "**Вывод**:\n",
    "\n",
    "Как показала практика, для этой задачи нужно использовать **машинное обучение**, поскольку мы обнаружили наличие закономерностей, которые модели, кстати, очень успешно находят. Dummy-предсказания не обеспечат ни точности, ни равномерного распределения ошибок.\n",
    "\n",
    "**Машинное обучение — это то что я предпочту для выполнения этого задания.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*P.S: Прошу прощения за задержку в сдаче, учил и делал на столько, на сколько позволяли возможности.. Спасибо за столь интересный и содержательный курс! <3*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
